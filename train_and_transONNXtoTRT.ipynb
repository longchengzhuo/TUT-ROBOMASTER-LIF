{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/longchengzhuo/TUT-ROBOMASTER-LIF/blob/main/train_and_transONNXtoTRT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/newnewBinaryImageOfArmor.zip /content\n",
        "!unzip newnewBinaryImageOfArmor.zip"
      ],
      "metadata": {
        "id": "J_BLJ-ZU0FE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libprotobuf-dev protobuf-compiler\n",
        "!pip install onnx"
      ],
      "metadata": {
        "id": "5r09gXnZfVJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf /content/newnewBinaryImageOfArmor/wrongpic"
      ],
      "metadata": {
        "id": "YO-01fgn6TfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2分类\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "batchsize = 256\n",
        "num_workers = 2\n",
        "device = torch.device('cuda:0')\n",
        "image_size = (32, 32)\n",
        "idx2name = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\", 5: \"base\", 6: \"outpost\", 7: \"sentry\", 8: \"wrongpic\"}\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, mode=\"train\"):\n",
        "        self.root = \"/content/newnewBinaryImageOfArmor\"\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((32, 32)),\n",
        "            # transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "        clazs = os.listdir(self.root)\n",
        "        self.picpaths = []\n",
        "        self.images = []\n",
        "        for claz in clazs:\n",
        "            paths = os.listdir(os.path.join(self.root, claz))\n",
        "            for path in paths:\n",
        "                self.picpaths.append(os.path.join(self.root, claz, path))\n",
        "        for path in self.picpaths:\n",
        "            with open(path, \"rb\") as fp:\n",
        "                tmp = Image.open(fp)\n",
        "                tmp = tmp.convert('L')\n",
        "                self.images.append(np.array(tmp))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        picpath = self.picpaths[idx]\n",
        "        img = self.transform(self.images[idx])\n",
        "        label = picpath.split(\"/\")[-2]\n",
        "        if label == \"wrongpic\":\n",
        "            label = 0\n",
        "        else:\n",
        "            label = 1\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.picpaths)\n",
        "\n",
        "\n",
        "class QBasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * expansion),\n",
        "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.ReLU6()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x.clone()) + x\n",
        "\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    '''\n",
        "        Designed by QPC, aimed at a binary (32*32) input, and 2 classes classification.\n",
        "        This is extraodinarily small so that it's necessary to design a special net.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.inblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
        "        self.down_sample1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
        "        self.down_sample2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.outblock = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inblock(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.down_sample1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.down_sample2(x)\n",
        "        x = self.down_sample3(x)\n",
        "        x = self.down_sample4(x)\n",
        "        x = x.view(-1, 128)\n",
        "        x = self.outblock(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "#%%\n",
        "if __name__ == '__main__':\n",
        "    dataset = ImageDataset()  # 实例\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batchsize, num_workers=num_workers, shuffle=True)\n",
        "    for img, label in dataset:\n",
        "        print(img.shape)  # [bs, channels, height, width]\n",
        "        break\n",
        "    dnn = QNet()\n",
        "    dnn.to(device)\n",
        "    # 定义损失函数\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    loss_function.to(device)\n",
        "    # 定义优化器\n",
        "    optimizer = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
        "    log_train_acc = []\n",
        "    # 进行迭代\n",
        "    print(\"start training...\")\n",
        "    for i in range(50):\n",
        "        # 训练\n",
        "        dnn.train()\n",
        "        total_train_acc = 0.0\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = dnn(imgs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            total_train_acc += ((outputs.argmax(1) == labels).sum()).item()\n",
        "            # 反向传播\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(\"{}th epoch. train_acc:{:.4f}\".format(i, total_train_acc / len(dataset)))\n",
        "        log_train_acc.append(total_train_acc / len(dataset))\n",
        "    print(len(dataset))\n",
        "    torch.save(dnn.state_dict(), \"./\" + \"2Binary_classification\" + \".pth\")\n",
        "\n",
        "    plt.plot(log_train_acc)\n",
        "    plt.title('Accuracy')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "_hs4nveL0q46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "MoSPcPPTGwO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8分类\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "batchsize = 256\n",
        "num_workers = 2\n",
        "device = torch.device('cuda:0')\n",
        "image_size = (32, 32)\n",
        "idx2name = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\", 5: \"base\", 6: \"outpost\", 7: \"sentry\", 8: \"wrongpic\"}\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, mode=\"train\"):\n",
        "        self.root = \"/content/newnewBinaryImageOfArmor\"\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((32, 32)),\n",
        "            # transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "        clazs = os.listdir(self.root)\n",
        "        self.picpaths = []\n",
        "        self.images = []\n",
        "        for claz in clazs:\n",
        "            paths = os.listdir(os.path.join(self.root, claz))\n",
        "            for path in paths:\n",
        "                self.picpaths.append(os.path.join(self.root, claz, path))\n",
        "        for path in self.picpaths:\n",
        "            with open(path, \"rb\") as fp:\n",
        "                tmp = Image.open(fp)\n",
        "                tmp = tmp.convert('L')\n",
        "                self.images.append(np.array(tmp))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        picpath = self.picpaths[idx]\n",
        "        img = self.transform(self.images[idx])\n",
        "        label = int(picpath.split(\"/\")[-2])-1\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.picpaths)\n",
        "\n",
        "\n",
        "class QBasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * expansion),\n",
        "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.ReLU6()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x.clone()) + x\n",
        "\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    '''\n",
        "        Designed by QPC, aimed at a binary (32*32) input, and 2 classes classification.\n",
        "        This is extraodinarily small so that it's necessary to design a special net.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, num_classes=11):\n",
        "        super().__init__()\n",
        "        self.inblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
        "        self.down_sample1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
        "        self.down_sample2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.outblock = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inblock(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.down_sample1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.down_sample2(x)\n",
        "        x = self.down_sample3(x)\n",
        "        x = self.down_sample4(x)\n",
        "        x = x.view(-1, 128)\n",
        "        x = self.outblock(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "#%%\n",
        "if __name__ == '__main__':\n",
        "    dataset = ImageDataset()  # 实例\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batchsize, num_workers=num_workers, shuffle=True)\n",
        "    for img, label in dataset:\n",
        "        print(img.shape)  # [bs, channels, height, width]\n",
        "        break\n",
        "    dnn = QNet()\n",
        "    dnn.to(device)\n",
        "    # 定义损失函数\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    loss_function.to(device)\n",
        "    # 定义优化器\n",
        "    optimizer = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
        "    log_train_acc = []\n",
        "    # 进行迭代\n",
        "    print(\"start training...\")\n",
        "    for i in range(50):\n",
        "        # 训练\n",
        "        dnn.train()\n",
        "        total_train_acc = 0.0\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = dnn(imgs)\n",
        "            print(outputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            total_train_acc += ((outputs.argmax(1) == labels).sum()).item()\n",
        "            # 反向传播\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(\"{}th epoch. train_acc:{:.4f}\".format(i, total_train_acc / len(dataset)))\n",
        "        log_train_acc.append(total_train_acc / len(dataset))\n",
        "    print(len(dataset))\n",
        "    torch.save(dnn.state_dict(), \"./\" + \"11Binary_classification\" + \".pth\")\n",
        "\n",
        "    plt.plot(log_train_acc)\n",
        "    plt.title('Accuracy')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "bgGiyEqg4vj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T6wCycbajzP"
      },
      "outputs": [],
      "source": [
        "#8分类\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "batchsize = 32\n",
        "num_workers = 2\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "\n",
        "\n",
        "class QBasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * expansion),\n",
        "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.ReLU6()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x.clone()) + x\n",
        "\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, num_classes=11):\n",
        "        super().__init__()\n",
        "        self.inblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
        "        self.down_sample1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
        "        self.down_sample2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.outblock = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inblock(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.down_sample1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.down_sample2(x)\n",
        "        x = self.down_sample3(x)\n",
        "        x = self.down_sample4(x)\n",
        "        x = x.view(-1, 128)\n",
        "        x = self.outblock(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dnn = QNet()\n",
        "    dnn.to(device)\n",
        "    dnn.eval()\n",
        "    input_shape = (1, 32, 32)\n",
        "    batch_size = 1\n",
        "    x = torch.randn(batch_size, *input_shape).to(device)  # 生成张量\n",
        "    # 加载模型\n",
        "    dnn.load_state_dict(torch.load(\"/content/11Binary_classification.pth\", map_location=device))\n",
        "    # 模型转换\n",
        "    input_name = \"inputs\"\n",
        "    output_name = \"outputs\"\n",
        "    export_onnx_file = \"./11Binary_classification.onnx\"  # 目的ONNX文件名\n",
        "    torch.onnx.export(dnn,\n",
        "                      x,\n",
        "                      export_onnx_file,  # 设置onnx模型输出路径, 例如：c: / xxx.onnx\n",
        "                      opset_version=10,\n",
        "                      do_constant_folding=True,  # 是否执行常量折叠优化\n",
        "                      export_params=True,\n",
        "                      verbose=True,\n",
        "                      input_names=[input_name],\n",
        "                      output_names=[output_name],\n",
        "                      dynamic_axes={\n",
        "                          input_name: {0: 'batch_size'},\n",
        "                          output_name: {0: 'batch_size'}})\n",
        "                      \n",
        "    print(\"-----pth to onnx trans successed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go2o1lsm639D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a395a90-b7df-40b1-9637-7c6f2663a72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "-----pth to onnx trans successed.\n"
          ]
        }
      ],
      "source": [
        "#2分类\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "num_workers = 2\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "\n",
        "\n",
        "class QBasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * expansion),\n",
        "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
        "                      padding=1, bias=False),\n",
        "            nn.ReLU6()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x.clone()) + x\n",
        "\n",
        "\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.inblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
        "        self.down_sample1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
        "        self.down_sample2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down_sample4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.outblock = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inblock(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.down_sample1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.down_sample2(x)\n",
        "        x = self.down_sample3(x)\n",
        "        x = self.down_sample4(x)\n",
        "        x = x.view(-1, 128)\n",
        "        x = self.outblock(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dnn = QNet()\n",
        "    dnn.to(device)\n",
        "    dnn.eval()\n",
        "    input_shape = (1, 32, 32)\n",
        "    batch_size = 1\n",
        "    x = torch.randn(batch_size, *input_shape).to(device)  # 生成张量\n",
        "    # 加载模型\n",
        "    dnn.load_state_dict(torch.load(\"/content/2Binary_classification.pth\", map_location=device))\n",
        "    # 模型转换\n",
        "    input_name = \"inputs\"\n",
        "    output_name = \"outputs\"\n",
        "    export_onnx_file = \"./2Binary_classification.onnx\"  # 目的ONNX文件名\n",
        "    torch.onnx.export(dnn,\n",
        "                      x,\n",
        "                      export_onnx_file,  # 设置onnx模型输出路径, 例如：c: / xxx.onnx\n",
        "                      opset_version=10,\n",
        "                      do_constant_folding=True,  # 是否执行常量折叠优化\n",
        "                      export_params=True,\n",
        "                      verbose=True,\n",
        "                      input_names=[input_name],\n",
        "                      output_names=[output_name],\n",
        "                      dynamic_axes={\n",
        "                          input_name: {0: 'batch_size'},\n",
        "                          output_name: {0: 'batch_size'}})\n",
        "                      \n",
        "    print(\"-----pth to onnx trans successed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-aOn2Ej83PF",
        "outputId": "e588e5de-1519-474d-8e07-69be7b4f7fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/11Binary_classification.onnx /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "-YMqLtNh4TD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/Binary_classification.pth /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "AFHV8ukf6BOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/BinaryImageOfArmor.zip"
      ],
      "metadata": {
        "id": "RoDMj8eykgUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmBiWOz28SFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}