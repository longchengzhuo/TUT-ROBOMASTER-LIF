{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/longchengzhuo/TUT-ROBOMASTER-LIF/blob/main/train_and_transONNXtoTRT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -r /content/drive/MyDrive/newnewBinaryImageOfArmor.zip /content\n",
    "!unzip newnewBinaryImageOfArmor.zip"
   ],
   "metadata": {
    "id": "J_BLJ-ZU0FE8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!sudo apt-get install libprotobuf-dev protobuf-compiler\n",
    "!pip install onnx"
   ],
   "metadata": {
    "id": "5r09gXnZfVJd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rm -rf /content/newnewBinaryImageOfArmor/wrongpic"
   ],
   "metadata": {
    "id": "YO-01fgn6TfW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#2分类\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batchsize = 256\n",
    "num_workers = 2\n",
    "device = torch.device('cuda:0')\n",
    "image_size = (32, 32)\n",
    "idx2name = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\", 5: \"base\", 6: \"outpost\", 7: \"sentry\", 8: \"wrongpic\"}\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        self.root = \"/content/newnewBinaryImageOfArmor\"\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((32, 32)),\n",
    "            # transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        clazs = os.listdir(self.root)\n",
    "        self.picpaths = []\n",
    "        self.images = []\n",
    "        for claz in clazs:\n",
    "            paths = os.listdir(os.path.join(self.root, claz))\n",
    "            for path in paths:\n",
    "                self.picpaths.append(os.path.join(self.root, claz, path))\n",
    "        for path in self.picpaths:\n",
    "            with open(path, \"rb\") as fp:\n",
    "                tmp = Image.open(fp)\n",
    "                tmp = tmp.convert('L')\n",
    "                self.images.append(np.array(tmp))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        picpath = self.picpaths[idx]\n",
    "        img = self.transform(self.images[idx])\n",
    "        label = picpath.split(\"/\")[-2]\n",
    "        if label == \"wrongpic\":\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.picpaths)\n",
    "\n",
    "\n",
    "class QBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * expansion),\n",
    "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x.clone()) + x\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    '''\n",
    "        Designed by QPC, aimed at a binary (32*32) input, and 2 classes classification.\n",
    "        This is extraodinarily small so that it's necessary to design a special net.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.inblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
    "        self.down_sample1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
    "        self.down_sample2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.outblock = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inblock(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.down_sample1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.down_sample2(x)\n",
    "        x = self.down_sample3(x)\n",
    "        x = self.down_sample4(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.outblock(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "##%%\n",
    "if __name__ == '__main__':\n",
    "    dataset = ImageDataset()  # 实例\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batchsize, num_workers=num_workers, shuffle=True)\n",
    "    for img, label in dataset:\n",
    "        print(img.shape)  # [bs, channels, height, width]\n",
    "        break\n",
    "    dnn = QNet()\n",
    "    dnn.to(device)\n",
    "    # 定义损失函数\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function.to(device)\n",
    "    # 定义优化器\n",
    "    optimizer = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
    "    log_train_acc = []\n",
    "    # 进行迭代\n",
    "    print(\"start training...\")\n",
    "    for i in range(50):\n",
    "        # 训练\n",
    "        dnn.train()\n",
    "        total_train_acc = 0.0\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = dnn(imgs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_train_acc += ((outputs.argmax(1) == labels).sum()).item()\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"{}th epoch. train_acc:{:.4f}\".format(i, total_train_acc / len(dataset)))\n",
    "        log_train_acc.append(total_train_acc / len(dataset))\n",
    "    print(len(dataset))\n",
    "    torch.save(dnn.state_dict(), \"./\" + \"2Binary_classification\" + \".pth\")\n",
    "\n",
    "    plt.plot(log_train_acc)\n",
    "    plt.title('Accuracy')\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "_hs4nveL0q46"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python --version"
   ],
   "metadata": {
    "id": "MoSPcPPTGwO1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#8分类\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batchsize = 256\n",
    "num_workers = 2\n",
    "device = torch.device('cuda:0')\n",
    "image_size = (32, 32)\n",
    "idx2name = {0: \"1\", 1: \"2\", 2: \"3\", 3: \"4\", 4: \"5\", 5: \"base\", 6: \"outpost\", 7: \"sentry\", 8: \"wrongpic\"}\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        self.root = \"/content/newnewBinaryImageOfArmor\"\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((32, 32)),\n",
    "            # transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        clazs = os.listdir(self.root)\n",
    "        self.picpaths = []\n",
    "        self.images = []\n",
    "        for claz in clazs:\n",
    "            paths = os.listdir(os.path.join(self.root, claz))\n",
    "            for path in paths:\n",
    "                self.picpaths.append(os.path.join(self.root, claz, path))\n",
    "        for path in self.picpaths:\n",
    "            with open(path, \"rb\") as fp:\n",
    "                tmp = Image.open(fp)\n",
    "                tmp = tmp.convert('L')\n",
    "                self.images.append(np.array(tmp))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        picpath = self.picpaths[idx]\n",
    "        img = self.transform(self.images[idx])\n",
    "        label = int(picpath.split(\"/\")[-2])-1\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.picpaths)\n",
    "\n",
    "\n",
    "class QBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * expansion),\n",
    "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x.clone()) + x\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    '''\n",
    "        Designed by QPC, aimed at a binary (32*32) input, and 2 classes classification.\n",
    "        This is extraodinarily small so that it's necessary to design a special net.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.inblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
    "        self.down_sample1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
    "        self.down_sample2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.outblock = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inblock(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.down_sample1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.down_sample2(x)\n",
    "        x = self.down_sample3(x)\n",
    "        x = self.down_sample4(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.outblock(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "##%%\n",
    "if __name__ == '__main__':\n",
    "    dataset = ImageDataset()  # 实例\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batchsize, num_workers=num_workers, shuffle=True)\n",
    "    for img, label in dataset:\n",
    "        print(img.shape)  # [bs, channels, height, width]\n",
    "        break\n",
    "    dnn = QNet()\n",
    "    dnn.to(device)\n",
    "    # 定义损失函数\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function.to(device)\n",
    "    # 定义优化器\n",
    "    optimizer = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
    "    log_train_acc = []\n",
    "    # 进行迭代\n",
    "    print(\"start training...\")\n",
    "    for i in range(50):\n",
    "        # 训练\n",
    "        dnn.train()\n",
    "        total_train_acc = 0.0\n",
    "        for imgs, labels in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = dnn(imgs)\n",
    "            print(outputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            total_train_acc += ((outputs.argmax(1) == labels).sum()).item()\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"{}th epoch. train_acc:{:.4f}\".format(i, total_train_acc / len(dataset)))\n",
    "        log_train_acc.append(total_train_acc / len(dataset))\n",
    "    print(len(dataset))\n",
    "    torch.save(dnn.state_dict(), \"./\" + \"11Binary_classification\" + \".pth\")\n",
    "\n",
    "    plt.plot(log_train_acc)\n",
    "    plt.title('Accuracy')\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "bgGiyEqg4vj-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T6wCycbajzP"
   },
   "outputs": [],
   "source": [
    "#8分类\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batchsize = 32\n",
    "num_workers = 2\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "class QBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * expansion),\n",
    "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x.clone()) + x\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.inblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
    "        self.down_sample1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
    "        self.down_sample2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.outblock = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inblock(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.down_sample1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.down_sample2(x)\n",
    "        x = self.down_sample3(x)\n",
    "        x = self.down_sample4(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.outblock(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dnn = QNet()\n",
    "    dnn.to(device)\n",
    "    dnn.eval()\n",
    "    input_shape = (1, 32, 32)\n",
    "    batch_size = 1\n",
    "    x = torch.randn(batch_size, *input_shape).to(device)  # 生成张量\n",
    "    # 加载模型\n",
    "    dnn.load_state_dict(torch.load(\"/content/11Binary_classification.pth\", map_location=device))\n",
    "    # 模型转换\n",
    "    input_name = \"inputs\"\n",
    "    output_name = \"outputs\"\n",
    "    export_onnx_file = \"./11Binary_classification.onnx\"  # 目的ONNX文件名\n",
    "    torch.onnx.export(dnn,\n",
    "                      x,\n",
    "                      export_onnx_file,  # 设置onnx模型输出路径, 例如：c: / xxx.onnx\n",
    "                      opset_version=10,\n",
    "                      do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "                      export_params=True,\n",
    "                      verbose=True,\n",
    "                      input_names=[input_name],\n",
    "                      output_names=[output_name],\n",
    "                      dynamic_axes={\n",
    "                          input_name: {0: 'batch_size'},\n",
    "                          output_name: {0: 'batch_size'}})\n",
    "                      \n",
    "    print(\"-----pth to onnx trans successed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go2o1lsm639D",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8a395a90-b7df-40b1-9637-7c6f2663a72e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "-----pth to onnx trans successed.\n"
     ]
    }
   ],
   "source": [
    "#2分类\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "num_workers = 2\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "class QBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels * expansion, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * expansion),\n",
    "            nn.Conv2d(in_channels=out_channels * expansion, out_channels=out_channels, kernel_size=3, stride=1,\n",
    "                      padding=1, bias=False),\n",
    "            nn.ReLU6()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x.clone()) + x\n",
    "\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.inblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block1 = QBasicBlock(in_channels=16, out_channels=16, expansion=4)\n",
    "        self.down_sample1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.block2 = QBasicBlock(in_channels=32, out_channels=32, expansion=4)\n",
    "        self.down_sample2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=4, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down_sample4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.outblock = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inblock(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.down_sample1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.down_sample2(x)\n",
    "        x = self.down_sample3(x)\n",
    "        x = self.down_sample4(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.outblock(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dnn = QNet()\n",
    "    dnn.to(device)\n",
    "    dnn.eval()\n",
    "    input_shape = (1, 32, 32)\n",
    "    batch_size = 1\n",
    "    x = torch.randn(batch_size, *input_shape).to(device)  # 生成张量\n",
    "    # 加载模型\n",
    "    dnn.load_state_dict(torch.load(\"/content/2Binary_classification.pth\", map_location=device))\n",
    "    # 模型转换\n",
    "    input_name = \"inputs\"\n",
    "    output_name = \"outputs\"\n",
    "    export_onnx_file = \"./2Binary_classification.onnx\"  # 目的ONNX文件名\n",
    "    torch.onnx.export(dnn,\n",
    "                      x,\n",
    "                      export_onnx_file,  # 设置onnx模型输出路径, 例如：c: / xxx.onnx\n",
    "                      opset_version=10,\n",
    "                      do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "                      export_params=True,\n",
    "                      verbose=True,\n",
    "                      input_names=[input_name],\n",
    "                      output_names=[output_name],\n",
    "                      dynamic_axes={\n",
    "                          input_name: {0: 'batch_size'},\n",
    "                          output_name: {0: 'batch_size'}})\n",
    "                      \n",
    "    print(\"-----pth to onnx trans successed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-aOn2Ej83PF",
    "outputId": "e588e5de-1519-474d-8e07-69be7b4f7fc7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!cp /content/11Binary_classification.onnx /content/drive/MyDrive"
   ],
   "metadata": {
    "id": "-YMqLtNh4TD6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp /content/Binary_classification.pth /content/drive/MyDrive"
   ],
   "metadata": {
    "id": "AFHV8ukf6BOl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -rf /content/BinaryImageOfArmor.zip"
   ],
   "metadata": {
    "id": "RoDMj8eykgUZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "lmBiWOz28SFY"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
